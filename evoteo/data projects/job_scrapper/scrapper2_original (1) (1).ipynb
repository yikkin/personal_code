{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans quelle ville voulez-vous effectuer votre recherche?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " paris \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quel métier voulez-vous chercher?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " data scientist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combien de d offres voulez-vous voir?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/lib/python3.6/site-packages/bs4/__init__.py:179: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "#importation de modules\n",
    "import requests\n",
    "import bs4\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#methode de scrapping \n",
    "def scrap_jobs(city , job_title ,nb_post):\n",
    "    columns = [\"city\", \"job_title\", \"company_name\", \"location\",\"summary\"]\n",
    "    sample_df = pd.DataFrame(columns = columns)\n",
    "    cumul_job_post = []\n",
    "    for start in range(0, nb_post):\n",
    "        page = requests.get(\"http://www.indeed.fr/jobs?q=\"+job_title+\"&l=\" + str(city) + \"&start=\" + str(start))\n",
    "        URL = \"http://www.indeed.fr/jobs?q=\"+job_title+\"&l=\" + str(city) + \"&start=\" + str(start)\n",
    "        \n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "        for div,div1 in itertools.zip_longest(soup.find_all(name=\"div\", attrs={\"class\":\"row\"}) , soup.find_all(name=\"div\", attrs={\"class\":\"date\"})):\n",
    "            \n",
    "            \n",
    "            job_post = []\n",
    "            \n",
    "            job_post.append(city)\n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "                job_post.append(a[\"title\"])\n",
    "                #grabbing company name\n",
    "                company = div.find_all(name=\"span\", attrs={\"class\":\"company\"}) \n",
    "\n",
    "            if len(company) > 0: \n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip()) \n",
    "            else: \n",
    "                sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "                for span in sec_try:\n",
    "                    job_post.append(span.text)\n",
    "            #grabbing location        \n",
    "            c = div.findAll(\"span\", attrs={\"class\": \"location\"})\n",
    "            d = div.findAll(\"span\", attrs={\"class\": \"summary\"})\n",
    "            \n",
    "            #grabbing date\n",
    "            e = div.findAll(\"span\" , attrs ={\"class\" : \"date\"})\n",
    "            \n",
    "            for spanc , spand in zip(c , d):\n",
    "                try:\n",
    "                    job_post.append(spanc.text)\n",
    "                    job_post.append(spand.text.strip())\n",
    "                except :\n",
    "                    job_post.append(city)\n",
    "                    job_post.append(\"none\")\n",
    "                    \n",
    "            for spane in e :\n",
    "                try:\n",
    "                    job_post.append(spane.text)\n",
    "                except:\n",
    "                    job_post.append(\"no date\")\n",
    "\n",
    "\n",
    "                cumul_job_post.append(job_post)\n",
    "                \n",
    "                cumul_job_post\n",
    "           \n",
    "    return cumul_job_post\n",
    "            \n",
    "                                \n",
    "max_results_per_city = 5\n",
    "\n",
    "print(\"dans quelle ville voulez-vous effectuer votre recherche?\")\n",
    "city = input()\n",
    "\n",
    "print(\"quel métier voulez-vous chercher?\")\n",
    "job_title = input()\n",
    "intitule = job_title\n",
    "\n",
    "print(\"combien de d offres voulez-vous voir?\")\n",
    "nb_post = input()\n",
    "nb_post = int(nb_post)\n",
    "\n",
    "if len(job_title.split(\" \")) > 1 :\n",
    "    job_title_decompose = job_title.split(\" \")\n",
    "    job_title = str(job_title_decompose[0]) +\"+\"+ str(job_title_decompose[1])\n",
    "\n",
    "set_jobs = scrap_jobs(city , job_title , nb_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frame_jobs = pd.DataFrame(columns = [\"city\" , \"position\" , \"company\" , \"localisation\" , \"summary\" , \"recency\"])\n",
    "    \n",
    "#pushing to dataframe (data absorbtion)\n",
    "frame_jobs[\"city\"] = list(map(lambda job_line : job_line[0] , set_jobs))\n",
    "frame_jobs[\"position\"] = list(map(lambda job_line : job_line[1] , set_jobs))\n",
    "frame_jobs[\"company\"] = list(map(lambda job_line : job_line[2] , set_jobs))\n",
    "frame_jobs[\"localisation\"] = list(map(lambda job_line : job_line[3] , set_jobs))\n",
    "frame_jobs[\"summary\"] = list(map(lambda job_line : job_line[4] , set_jobs))\n",
    "frame_jobs[\"recency\"] = list(map(lambda job_line : job_line[5] , set_jobs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>position</th>\n",
       "      <th>company</th>\n",
       "      <th>localisation</th>\n",
       "      <th>summary</th>\n",
       "      <th>recency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paris</td>\n",
       "      <td>Data Scientist Junior (H/F)</td>\n",
       "      <td>Ubisoft</td>\n",
       "      <td>Montreuil (93)</td>\n",
       "      <td>Supporter les Data Analysts en produisant des ...</td>\n",
       "      <td>il y a 12 jours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paris</td>\n",
       "      <td>Stage - Data Scientist-(H/F)</td>\n",
       "      <td>SG CIB</td>\n",
       "      <td>La Défense (92)</td>\n",
       "      <td>Environment Au sein du groupe Société Générale...</td>\n",
       "      <td>il y a 15 jours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paris</td>\n",
       "      <td>Consultant Data Scientist Débutant H/F</td>\n",
       "      <td>EY</td>\n",
       "      <td>La Défense (92)</td>\n",
       "      <td>Au sein d’EY Consulting, la division EY Analyt...</td>\n",
       "      <td>il y a 30+ jours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paris</td>\n",
       "      <td>Data Scientist (F/H)</td>\n",
       "      <td>AXA</td>\n",
       "      <td>Suresnes (92)</td>\n",
       "      <td>Good awareness on Data Management practices as...</td>\n",
       "      <td>il y a 4 jours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paris</td>\n",
       "      <td>ASSISTANT DATA SCIENTIST - H/F</td>\n",
       "      <td>La Banque de France</td>\n",
       "      <td>Paris (75)</td>\n",
       "      <td>Au sein du pôle Data science et Innovation, vo...</td>\n",
       "      <td>il y a 1 jour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city                                position              company  \\\n",
       "0  paris              Data Scientist Junior (H/F)              Ubisoft   \n",
       "1  paris             Stage - Data Scientist-(H/F)               SG CIB   \n",
       "2  paris   Consultant Data Scientist Débutant H/F                   EY   \n",
       "3  paris                     Data Scientist (F/H)                  AXA   \n",
       "4  paris           ASSISTANT DATA SCIENTIST - H/F  La Banque de France   \n",
       "\n",
       "      localisation                                            summary  \\\n",
       "0   Montreuil (93)  Supporter les Data Analysts en produisant des ...   \n",
       "1  La Défense (92)  Environment Au sein du groupe Société Générale...   \n",
       "2  La Défense (92)  Au sein d’EY Consulting, la division EY Analyt...   \n",
       "3    Suresnes (92)  Good awareness on Data Management practices as...   \n",
       "4       Paris (75)  Au sein du pôle Data science et Innovation, vo...   \n",
       "\n",
       "            recency  \n",
       "0   il y a 12 jours  \n",
       "1   il y a 15 jours  \n",
       "2  il y a 30+ jours  \n",
       "3    il y a 4 jours  \n",
       "4     il y a 1 jour  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_profil(city , job_title , nb_post):\n",
    "    columns = [\"city\", \"job_title\", \"company_name\", \"location\",\"summary\"]\n",
    "    #sample_df = pd.DataFrame(columns = columns)\n",
    "    cumul_job_post = []\n",
    "    for start in range(0, nb_post):\n",
    "        page = requests.get(\"http://www.indeed.fr/jobs?q=\"+job_title+\"&l=\" + str(city) + \"&start=\" + str(start))\n",
    "        URL = \"http://www.indeed.fr/jobs?q=\"+job_title+\"&l=\" + str(city) + \"&start=\" + str(start)\n",
    "        \n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            print(\"Found the URL:\", a['href'])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = '''<a href=\"some_url\">next</a>\n",
    "<span class=\"class\"><a href=\"another_url\">later</a></span>'''\n",
    "\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "for a in soup.find_all('a', href=True):\n",
    "    print(\"Found the URL:\", a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
